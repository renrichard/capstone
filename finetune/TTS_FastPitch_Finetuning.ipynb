{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "nemoenv",
   "language": "python",
   "name": "nemoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "TTS_FastPitch_Finetuning.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "history_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "WP4yUnh-xu1k",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b6d2eb6a-a449-454a-8f22-e5e5d85bc287"
   },
   "source": [
    "# create the data folder\n",
    "!mkdir ~/data\n",
    "\n",
    "# get the vcc2020 dataset\n",
    "!git -C ~/data clone https://github.com/nii-yamagishilab/VCC2020-database.git\n",
    "\n",
    "# create the directory to extract all the zips\n",
    "!rm -rf ~/data/VCC2020-database/extract\n",
    "!mkdir ~/data/VCC2020-database/extract\n",
    "\n",
    "!unzip /root/data/VCC2020-database/vcc2020_database_training_target_task1.zip -d /root/data/VCC2020-database/extract/\n",
    "!unzip /root/data/VCC2020-database/vcc2020_database_transcriptions.zip -d /root/data/VCC2020-database/extract/\n",
    "\n",
    "# install the preprocess repo\n",
    "!rm -rf capstone\n",
    "!git clone -b tts-finetune https://github.com/renrichard/capstone.git \n",
    "\n",
    "import sys\n",
    "sys.path.append('capstone')\n",
    "\n",
    "from capstone.preprocess.json.create_vcc_2020_json import create_vcc_2020_json\n",
    "create_vcc_2020_json()"
   ],
   "id": "WP4yUnh-xu1k",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'VCC2020-database'...\n",
      "remote: Enumerating objects: 25, done.\u001B[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001B[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001B[K\n",
      "remote: Total 25 (delta 4), reused 0 (delta 0), pack-reused 15\u001B[K\n",
      "Unpacking objects: 100% (25/25), done.\n",
      "Archive:  /root/data/VCC2020-database/vcc2020_database_training_target_task1.zip\n",
      "   creating: /root/data/VCC2020-database/extract/target_task1/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/._target_task1  \n",
      "   creating: /root/data/VCC2020-database/extract/target_task1/TEM2/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/._TEM2  \n",
      "   creating: /root/data/VCC2020-database/extract/target_task1/TEF1/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/._TEF1  \n",
      "   creating: /root/data/VCC2020-database/extract/target_task1/TEM1/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/._TEM1  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/dbcl-10.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/._dbcl-10.txt  \n",
      "   creating: /root/data/VCC2020-database/extract/target_task1/TEF2/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/._TEF2  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM2/E20012.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM2/._E20012.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF1/E20012.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF1/._E20012.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEM1/E20012.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEM1/._E20012.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20037.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20023.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10057.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10056.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20022.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20036.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20008.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20020.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20034.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10068.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10054.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10055.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10069.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20035.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20021.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20009.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20025.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20031.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20019.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10051.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20018.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20030.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20024.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20032.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20026.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10052.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10053.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20027.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20033.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20040.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20041.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20043.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20042.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20046.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20047.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20045.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20044.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20050.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20049.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20048.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20016.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20002.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10062.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10063.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20003.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20017.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20029.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20001.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20015.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10061.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10060.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20014.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20028.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20004.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20010.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20038.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10070.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10064.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10058.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10059.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10065.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20039.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20011.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20005.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20013.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20007.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10067.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E10066.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20006.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/target_task1/TEF2/E20012.wav  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/target_task1/TEF2/._E20012.wav  \n",
      "Archive:  /root/data/VCC2020-database/vcc2020_database_transcriptions.zip\n",
      "   creating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/._vcc2020_database_transcriptions  \n",
      "  inflating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/.DS_Store  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/._.DS_Store  \n",
      "   creating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/transcriptions_evaluation/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/._transcriptions_evaluation  \n",
      "   creating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/transcriptions_training/\n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/._transcriptions_training  \n",
      "  inflating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/transcriptions_evaluation/vcc2020_database_evaluation_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/transcriptions_evaluation/._vcc2020_database_evaluation_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/transcriptions_training/vcc2020_database_training_Eng_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/transcriptions_training/._vcc2020_database_training_Eng_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/transcriptions_training/vcc2020_database_training_Ger_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/transcriptions_training/._vcc2020_database_training_Ger_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/transcriptions_training/vcc2020_database_training_Man_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/transcriptions_training/._vcc2020_database_training_Man_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/vcc2020_database_transcriptions/transcriptions_training/vcc2020_database_training_Fin_transcriptions.txt  \n",
      "  inflating: /root/data/VCC2020-database/extract/__MACOSX/vcc2020_database_transcriptions/transcriptions_training/._vcc2020_database_training_Fin_transcriptions.txt  \n",
      "Cloning into 'capstone'...\n",
      "remote: Enumerating objects: 84, done.\u001B[K\n",
      "remote: Counting objects: 100% (84/84), done.\u001B[K\n",
      "remote: Compressing objects: 100% (59/59), done.\u001B[K\n",
      "remote: Total 84 (delta 30), reused 72 (delta 22), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (84/84), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d0bbac2"
   },
   "source": [
    "# Finetuning FastPitch for a new speaker"
   ],
   "id": "8d0bbac2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d063299"
   },
   "source": [
    "In this tutorial, we will finetune a single speaker FastPitch (with alignment) model on limited amount of new speaker's data. We cover two finetuning techniques: \n",
    "1. We finetune the model parameters only on new speaker's text and speech pairs; \n",
    "2. We add a learnable speaker embedding layer to the model, and finetune on a mixture of original speaker's and new speaker's data.\n",
    "\n",
    "We will first prepare filelists containing the audiopaths and text of the samples on which we wish to finetune the model, then generate and run a training command to finetune Fastpitch on 5 mins of data, and finally synthesize the audio from the trained checkpoint."
   ],
   "id": "2d063299"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2502cf61"
   },
   "source": [
    "## Creating filelists for training"
   ],
   "id": "2502cf61"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81fa2c02"
   },
   "source": [
    "We will first create filelists of audio on which we wish to finetune the FastPitch model. We will create two kinds of filelists, one which contains only the audio files of the new speaker and one which contains the mixed audio files of the new speaker and the speaker used for training the pre-trained FastPitch Checkpoint."
   ],
   "id": "81fa2c02"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b7b1563d"
   },
   "source": [
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import IPython.display as ipd\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from capstone.preprocess.json.vcc_2020_paths import data_dir, filelist_dir, exp_base_dir\n",
    "\n",
    "def make_sub_file_list(speaker_id, num_samples, total_duration_mins, seed=42):\n",
    "\t\"\"\"\n",
    "\tCreates a subset of training data for a HiFiTTS speaker. Specify either the num_samples or total_duration_mins\n",
    "\tSaves the filelist in the filelist_dir. split is either \"train\" or \"dev\"\n",
    "\n",
    "\tArguments:\n",
    "\tspeaker_id -- speaker id of the new HiFiTTS speaker\n",
    "\tclean_other -- \"clean\" or \"other\" depending on type of data of new HiFiTTS speaker\n",
    "\tsplit -- \"train\" or \"dev\"\n",
    "\tnum_samples -- Number samples of new speaker (set None if specifying total_duration_mins)\n",
    "\ttotal_duration_mins -- Total duration of new speaker's data (set None if specifying num_samples)\n",
    "\t\"\"\"\n",
    "\tfile_list_name = \"{}_metadata.json\".format(speaker_id)\n",
    "\twith open(os.path.join(data_dir, file_list_name), 'r') as f:\n",
    "\t\tall_records = [json.loads(l) for l in f.read().split(\"\\n\") if len(l) > 0]\n",
    "\trandom.seed(seed)\n",
    "\trandom.shuffle(all_records)\n",
    "\n",
    "\tif num_samples is not None and total_duration_mins is None:\n",
    "\t\tsub_records = all_records[:num_samples]\n",
    "\t\tfname_extension = \"ns_{}\".format(num_samples)\n",
    "\telif num_samples is None and total_duration_mins is not None:\n",
    "\t\tsub_record_duration = 0.0\n",
    "\t\tsub_records = []\n",
    "\t\tfor r in all_records:\n",
    "\t\t\tsub_record_duration += r['duration']\n",
    "\t\t\tif sub_record_duration > total_duration_mins * 60.0:\n",
    "\t\t\t\tprint(\"Duration reached {} mins using {} records\".format(total_duration_mins, len(sub_records)))\n",
    "\t\t\t\tbreak\n",
    "\t\t\tsub_records.append(r)\n",
    "\t\tfname_extension = \"dur_{}_mins\".format(int(round(total_duration_mins)))\n",
    "\telif num_samples is None and total_duration_mins is None:\n",
    "\t\tsub_records = all_records\n",
    "\t\tfname_extension = \"ns_all\"\n",
    "\telse:\n",
    "\t\traise NotImplementedError()\n",
    "\tprint(\"num sub records\", len(sub_records))\n",
    "\n",
    "\tif not os.path.exists(filelist_dir):\n",
    "\t\tos.makedirs(filelist_dir)\n",
    "\n",
    "\ttarget_fp = os.path.join(filelist_dir, \"{}_metadata_{}_local.json\".format(speaker_id, fname_extension))\n",
    "\twith open(target_fp, 'w') as f:\n",
    "\t\tfor record in json.loads(json.dumps(sub_records)):\n",
    "\t\t\trecord['audio_filepath'] = os.path.join(data_dir, record['audio_filepath'])\n",
    "\t\t\tf.write(json.dumps(record) + \"\\n\")\n",
    "\n"
   ],
   "id": "b7b1563d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5c635928",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "62a29d7a-3703-46eb-8e6c-654c3d0b5a64"
   },
   "source": [
    "make_sub_file_list('TEF1', None, 5)"
   ],
   "id": "5c635928",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num sub records 70\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef75d1d5"
   },
   "source": [
    "## Finetuning the model on filelists"
   ],
   "id": "ef75d1d5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c8b13b8"
   },
   "source": [
    "To finetune the FastPitch model on the above created filelists, we use `examples/tts/fastpitch2_finetune.py` script to train the models with the `fastpitch_align_44100.yaml` configuration. This configuration file has been defined for 44100Hz HiFiGan dataset audio. The function `generate_training_command` in this notebook can be used to generate a training command for a given speaker and finetuning technique."
   ],
   "id": "6c8b13b8"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a57fcfec"
   },
   "source": [
    "# pitch statistics of the new speakers\n",
    "# These can be computed from the pitch contours extracted using librosa yin\n",
    "# Finetuning can still work without these, but we get better results using speaker specific pitch stats\n",
    "# pitch_stats = {\n",
    "#     92 : {\n",
    "#         'mean' : 214.5, # female speaker\n",
    "#         'std' : 30.9,\n",
    "#         'fmin' : 80,\n",
    "#         'fmax' : 512\n",
    "#     },\n",
    "#     6097 : {\n",
    "#         'mean' : 121.9, # male speaker\n",
    "#         'std' : 23.1,\n",
    "#         'fmin' : 30,\n",
    "#         'fmax' : 512\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "def generate_training_command(new_speaker_id, duration_mins, mixing_enabled, original_speaker_id, ckpt, use_new_pitch_stats=False):\n",
    "    \"\"\"\n",
    "    Generates the training command string to be run from the NeMo/ directory. Assumes we have created the finetuning filelists\n",
    "    using the instructions given above.\n",
    "    \n",
    "    Arguments:\n",
    "    new_speaker_id -- speaker id of the new HiFiTTS speaker\n",
    "    duration_mins -- total minutes of the new speaker data (same as that used for creating the filelists)\n",
    "    mixing_enabled -- True or False depending on whether we want to mix the original speaker data or not\n",
    "    original_speaker_id -- speaker id of the original HiFiTTS speaker\n",
    "    use_new_pitch_stats -- whether to use pitch_stats dictionary given above or not\n",
    "    ckpt: Path to pretrained FastPitch checkpoint\n",
    "    \n",
    "    Returns:\n",
    "    Training command string\n",
    "    \"\"\"\n",
    "    def _find_epochs(duration_mins, mixing_enabled, n_orig=None):\n",
    "        # estimated num of epochs \n",
    "        if duration_mins == 5:\n",
    "            epochs = 1000\n",
    "        elif duration_mins == 30:\n",
    "            epochs = 300\n",
    "        elif duration_mins == 60:\n",
    "            epochs = 150\n",
    "        \n",
    "        if mixing_enabled:\n",
    "            if duration_mins == 5:\n",
    "                epochs = epochs/50 + 1\n",
    "            elif duration_mins == 30:\n",
    "                epochs = epochs/10 + 1\n",
    "            elif duration_mins == 60:\n",
    "                epochs = epochs/5 + 1\n",
    "        \n",
    "        return int(epochs)\n",
    "            \n",
    "            \n",
    "    if ckpt.endswith(\".nemo\"):\n",
    "        ckpt_arg_name = \"init_from_nemo_model\"\n",
    "    else:\n",
    "        ckpt_arg_name = \"init_from_ptl_ckpt\"\n",
    "    if not mixing_enabled:\n",
    "        train_dataset = \"{}_metadata_dur_{}_mins_local.json\".format(new_speaker_id, duration_mins)\n",
    "        val_dataset = \"{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id)\n",
    "        prior_folder = os.path.join(data_dir, \"Priors{}\".format(new_speaker_id))\n",
    "        exp_dir = \"{}_to_{}_no_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "        n_speakers = 1\n",
    "    else:\n",
    "        train_dataset = \"{}_mainifest_train_dur_{}_mins_local_mix_{}.json\".format(new_speaker_id, duration_mins, original_speaker_id)\n",
    "        val_dataset = \"{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id)\n",
    "        prior_folder = os.path.join(data_dir, \"Priors_{}_mix_{}\".format(new_speaker_id, original_speaker_id))\n",
    "        exp_dir = \"{}_to_{}_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "        n_speakers = 2\n",
    "    train_dataset = os.path.join(filelist_dir, train_dataset)\n",
    "    val_dataset = os.path.join(filelist_dir, val_dataset)\n",
    "    exp_dir = os.path.join(exp_base_dir, exp_dir)\n",
    "                                    \n",
    "    max_epochs = _find_epochs(duration_mins, mixing_enabled, n_orig=None)\n",
    "    config_name = \"fastpitch_align_44100.yaml\"\n",
    "    \n",
    "    training_command = \"python /content/capstone/finetune/fastpitch2_finetune.py --config-name={} train_dataset={} validation_datasets={} +{}={} trainer.max_epochs={} trainer.check_val_every_n_epoch=1 prior_folder={} model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir={} model.n_speakers={}\".format(\n",
    "        config_name, train_dataset, val_dataset, ckpt_arg_name, ckpt, max_epochs, prior_folder, exp_dir, n_speakers)\n",
    "    # if use_new_pitch_stats:\n",
    "    #     training_command += \" model.pitch_avg={} model.pitch_std={} model.pitch_fmin={} model.pitch_fmax={}\".format(\n",
    "    #         pitch_stats[new_speaker_id]['mean'], \n",
    "    #         pitch_stats[new_speaker_id]['std'],\n",
    "    #         pitch_stats[new_speaker_id]['fmin'],\n",
    "    #         pitch_stats[new_speaker_id]['fmax']\n",
    "    #     )\n",
    "    training_command += \" model.optim.lr=2e-4 ~model.optim.sched\"\n",
    "    return training_command\n",
    "    "
   ],
   "id": "a57fcfec",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f98c55af",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a9de45b1-b157-45bc-95ad-f45ce8008f75"
   },
   "source": [
    "new_speaker_id = \"TEF1\"\n",
    "duration_mins = 5\n",
    "mixing = False\n",
    "original_speaker_id = \"TEM1\"\n",
    "ckpt_path = \"/root/checkpoint\"\n",
    "print(generate_training_command(new_speaker_id, duration_mins, mixing, original_speaker_id, ckpt_path, True))"
   ],
   "id": "f98c55af",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "python /content/capstone/finetune/fastpitch2_finetune.py --config-name=fastpitch_align_44100.yaml train_dataset=/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json validation_datasets=/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/root/checkpoint trainer.max_epochs=1000 trainer.check_val_every_n_epoch=1 prior_folder=/root/data/VCC2020-database/extract/target_task1/json/PriorsTEF1 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins model.n_speakers=1 model.optim.lr=2e-4 ~model.optim.sched\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HxEuT8Pk9PCf",
    "outputId": "2580f95f-8d16-4099-9de9-73cca0c0a575"
   },
   "source": [
    "!pip install pytorch_lightning\n",
    "!apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
    "!pip install Cython\n",
    "!pip install nemo_toolkit['all']"
   ],
   "id": "HxEuT8Pk9PCf",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.4.7-py3-none-any.whl (923 kB)\n",
      "\u001B[K     || 923 kB 5.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.9.0+cu102)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.7.4.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.62.0)\n",
      "Collecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001B[K     || 829 kB 36.8 MB/s \n",
      "\u001B[?25hCollecting PyYAML>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001B[K     || 636 kB 38.0 MB/s \n",
      "\u001B[?25hCollecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.6.0)\n",
      "Collecting torchmetrics>=0.4.0\n",
      "  Downloading torchmetrics-0.5.1-py3-none-any.whl (282 kB)\n",
      "\u001B[K     || 282 kB 49.5 MB/s \n",
      "\u001B[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
      "\u001B[K     || 119 kB 49.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[K     || 1.3 MB 29.7 MB/s \n",
      "\u001B[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (2.4.7)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.39.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.5)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.34.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.6.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001B[K     || 294 kB 52.3 MB/s \n",
      "\u001B[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "\u001B[K     || 142 kB 47.8 MB/s \n",
      "\u001B[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.5.0)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=0d13508c80f9534b3fc69e5a888347dd43162df130c8d71a4f45e2ab2e3ce1e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built future\n",
      "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.8.1 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.1 pytorch-lightning-1.4.7 torchmetrics-0.5.1 yarl-1.6.3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "yaml"
        ]
       }
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 34.4 kB/88.7\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
      "\r0% [Waiting for headers] [1 InRelease 43.1 kB/88.7 kB 49%] [3 InRelease 3,626 B\r0% [Waiting for headers] [1 InRelease 60.5 kB/88.7 kB 68%] [Waiting for headers\r0% [3 InRelease gpgv 3,626 B] [Waiting for headers] [1 InRelease 63.4 kB/88.7 k\r0% [3 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "\r                                                                               \r0% [3 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
      "\r0% [3 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
      "\r0% [3 InRelease gpgv 3,626 B] [Waiting for headers] [6 InRelease 2,572 B/15.9 k\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "\r0% [3 InRelease gpgv 3,626 B] [Waiting for headers] [6 InRelease 2,572 B/15.9 k\r                                                                               \rGet:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,324 kB]\n",
      "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [567 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
      "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [717 kB]\n",
      "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,799 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [600 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
      "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [921 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,760 kB]\n",
      "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
      "Fetched 13.6 MB in 4s (3,687 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsndfile1 is already the newest version (1.0.28-4ubuntu0.18.04.2).\n",
      "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 89 not upgraded.\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n",
      "Collecting nemo_toolkit[all]\n",
      "  Downloading nemo_toolkit-1.3.0-py3-none-any.whl (2.4 MB)\n",
      "\u001B[K     || 2.4 MB 5.3 MB/s \n",
      "\u001B[?25hCollecting webdataset<=0.1.62,>=0.1.48\n",
      "  Downloading webdataset-0.1.62-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.8.2)\n",
      "Collecting grpcio-tools\n",
      "  Downloading grpcio_tools-1.40.0-cp37-cp37m-manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001B[K     || 2.5 MB 37.4 MB/s \n",
      "\u001B[?25hCollecting ruamel.yaml\n",
      "  Downloading ruamel.yaml-0.17.16-py3-none-any.whl (109 kB)\n",
      "\u001B[K     || 109 kB 39.3 MB/s \n",
      "\u001B[?25hCollecting transformers>=4.8.1\n",
      "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
      "\u001B[K     || 2.8 MB 35.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.12.1)\n",
      "Collecting sentencepiece<1.0.0\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[K     || 1.2 MB 36.2 MB/s \n",
      "\u001B[?25hCollecting onnx>=1.7.0\n",
      "  Downloading onnx-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
      "\u001B[K     || 12.3 MB 192 kB/s \n",
      "\u001B[?25hCollecting omegaconf>=2.1.0\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001B[K     || 74 kB 3.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.9.0+cu102)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.39.0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (4.62.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.22.2.post1)\n",
      "Requirement already satisfied: pytorch-lightning>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.4.7)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1rc0 in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.5.1)\n",
      "Collecting hydra-core>=1.1.0\n",
      "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001B[K     || 145 kB 53.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.51.2)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Collecting kaldi-io\n",
      "  Downloading kaldi_io-0.9.4-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.2.2)\n",
      "Collecting kaldiio\n",
      "  Downloading kaldiio-2.17.2.tar.gz (24 kB)\n",
      "Collecting sacremoses>=0.0.43\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001B[K     || 895 kB 45.7 MB/s \n",
      "\u001B[?25hCollecting g2p-en\n",
      "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001B[K     || 3.1 MB 34.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.2.5)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.1-py3-none-any.whl (235 kB)\n",
      "\u001B[K     || 235 kB 46.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.1.5)\n",
      "Collecting wordninja==2.0.0\n",
      "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
      "\u001B[K     || 541 kB 35.1 MB/s \n",
      "\u001B[?25hCollecting youtokentome>=1.0.5\n",
      "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
      "\u001B[K     || 1.7 MB 37.9 MB/s \n",
      "\u001B[?25hCollecting isort[requirements]<5\n",
      "  Downloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
      "\u001B[K     || 42 kB 1.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2019.12.20)\n",
      "Collecting kaldi-python-io\n",
      "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
      "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (2.1.0)\n",
      "Collecting torch-stft\n",
      "  Downloading torch_stft-0.1.4-py3-none-any.whl (6.2 kB)\n",
      "Collecting pyannote.metrics\n",
      "  Downloading pyannote.metrics-3.0.1-py3-none-any.whl (49 kB)\n",
      "\u001B[K     || 49 kB 5.7 MB/s \n",
      "\u001B[?25hCollecting sox\n",
      "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.10.0+cu102)\n",
      "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.8.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.1.0)\n",
      "Collecting pystoi\n",
      "  Downloading pystoi-0.3.3.tar.gz (7.0 kB)\n",
      "Collecting sphinxcontrib-bibtex\n",
      "  Downloading sphinxcontrib_bibtex-2.4.1-py3-none-any.whl (38 kB)\n",
      "Collecting parameterized\n",
      "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
      "Collecting pytest-runner\n",
      "  Using cached pytest_runner-5.3.1-py3-none-any.whl (7.1 kB)\n",
      "Collecting pypinyin\n",
      "  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001B[K     || 1.3 MB 36.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (21.0)\n",
      "Collecting nltk==3.6.2\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001B[K     || 1.5 MB 24.0 MB/s \n",
      "\u001B[?25hCollecting frozendict\n",
      "  Downloading frozendict-2.0.6-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.6.4)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.42.1)\n",
      "Collecting opencc\n",
      "  Downloading OpenCC-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (765 kB)\n",
      "\u001B[K     || 765 kB 44.4 MB/s \n",
      "\u001B[?25hCollecting boto3\n",
      "  Downloading boto3-1.18.42-py3-none-any.whl (131 kB)\n",
      "\u001B[K     || 131 kB 47.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (7.1.2)\n",
      "Collecting pyannote.core\n",
      "  Downloading pyannote.core-4.1-py3-none-any.whl (56 kB)\n",
      "\u001B[K     || 56 kB 4.3 MB/s \n",
      "\u001B[?25hCollecting pesq\n",
      "  Downloading pesq-0.0.3.tar.gz (35 kB)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (3.6.4)\n",
      "Collecting braceexpand\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.8.1)\n",
      "Collecting sacrebleu[ja]\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "\u001B[K     || 90 kB 8.9 MB/s \n",
      "\u001B[?25hCollecting black==19.10b0\n",
      "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
      "\u001B[K     || 97 kB 6.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.5.3)\n",
      "Collecting megatron-lm==2.2.0\n",
      "  Downloading megatron_lm-2.2.0-py3-none-any.whl (171 kB)\n",
      "\u001B[K     || 171 kB 50.8 MB/s \n",
      "\u001B[?25hCollecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001B[K     || 68 kB 6.6 MB/s \n",
      "\u001B[?25hCollecting pangu\n",
      "  Downloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (7.6.3)\n",
      "Collecting matplotlib>=3.3.2\n",
      "  Downloading matplotlib-3.4.3-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001B[K     || 10.3 MB 39.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (1.4.1)\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-1.6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "\u001B[K     || 2.0 MB 17.7 MB/s \n",
      "\u001B[?25hCollecting wandb\n",
      "  Downloading wandb-0.12.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001B[K     || 1.7 MB 34.7 MB/s \n",
      "\u001B[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from nemo_toolkit[all]) (0.10.3.post1)\n",
      "Collecting marshmallow\n",
      "  Downloading marshmallow-3.13.0-py2.py3-none-any.whl (47 kB)\n",
      "\u001B[K     || 47 kB 4.5 MB/s \n",
      "\u001B[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (1.4.4)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (21.2.0)\n",
      "Requirement already satisfied: click>=6.5 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (7.1.2)\n",
      "Collecting typed-ast>=1.4.0\n",
      "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
      "\u001B[K     || 743 kB 46.8 MB/s \n",
      "\u001B[?25hCollecting pathspec<1,>=0.6\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->nemo_toolkit[all]) (0.10.2)\n",
      "Collecting pybind11\n",
      "  Using cached pybind11-2.7.1-py2.py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from megatron-lm==2.2.0->nemo_toolkit[all]) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.2->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1.0->nemo_toolkit[all]) (5.2.2)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001B[K     || 112 kB 51.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf>=2.1.0->nemo_toolkit[all]) (5.4.1)\n",
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.4.10-py2.py3-none-any.whl (25 kB)\n",
      "Collecting pip-api\n",
      "  Downloading pip_api-0.0.21-py3-none-any.whl (107 kB)\n",
      "\u001B[K     || 107 kB 31.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->nemo_toolkit[all]) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.7.0->nemo_toolkit[all]) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.7.0->nemo_toolkit[all]) (3.17.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.18.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->nemo_toolkit[all]) (2.6.0)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.3.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->nemo_toolkit[all]) (2021.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (2.23.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (3.7.4.post0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (1.34.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (57.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.4.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (3.3.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (1.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (4.6.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (3.1.1)\n",
      "Collecting huggingface-hub>=0.0.12\n",
      "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
      "\u001B[K     || 52 kB 1.6 MB/s \n",
      "\u001B[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     || 3.3 MB 39.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->nemo_toolkit[all]) (3.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (5.1.0)\n",
      "Collecting botocore<1.22.0,>=1.21.42\n",
      "  Downloading botocore-1.21.42-py3-none-any.whl (7.9 MB)\n",
      "\u001B[K     || 7.9 MB 39.9 MB/s \n",
      "\u001B[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "\u001B[K     || 79 kB 8.4 MB/s \n",
      "\u001B[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001B[K     || 127 kB 49.1 MB/s \n",
      "\u001B[?25hCollecting distance>=0.1.3\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001B[K     || 180 kB 47.3 MB/s \n",
      "\u001B[?25hCollecting grpcio\n",
      "  Downloading grpcio-1.40.0-cp37-cp37m-manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001B[K     || 4.3 MB 32.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->nemo_toolkit[all]) (1.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->nemo_toolkit[all]) (3.5.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (5.5.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (5.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->nemo_toolkit[all]) (4.10.1)\n",
      "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (5.3.5)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (2.6.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.7.5)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (4.7.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (2.6.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (5.3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.11.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (5.6.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (22.2.1)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->nemo_toolkit[all]) (1.4.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->nemo_toolkit[all]) (2.1.9)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->nemo_toolkit[all]) (0.2.2)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->nemo_toolkit[all]) (0.34.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->nemo_toolkit[all]) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit[all]) (2.20)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.4.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (4.0.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.8.4)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->nemo_toolkit[all]) (2018.9)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from pip-api->isort[requirements]<5->nemo_toolkit[all]) (21.1.3)\n",
      "Collecting yarg\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from pipreqs->isort[requirements]<5->nemo_toolkit[all]) (0.6.2)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from pyannote.core->nemo_toolkit[all]) (2.4.0)\n",
      "Collecting simplejson>=3.8.1\n",
      "  Downloading simplejson-3.17.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
      "\u001B[K     || 129 kB 44.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics->nemo_toolkit[all]) (1.7.1)\n",
      "Collecting pyannote.database>=4.0.1\n",
      "  Downloading pyannote.database-4.1.1-py3-none-any.whl (41 kB)\n",
      "\u001B[K     || 41 kB 267 kB/s \n",
      "\u001B[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics->nemo_toolkit[all]) (0.8.9)\n",
      "Collecting typer[all]>=0.2.1\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.1->pyannote.metrics->nemo_toolkit[all]) (1.2.1)\n",
      "Collecting colorama<0.5.0,>=0.4.3\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting shellingham<2.0.0,>=1.3.0\n",
      "  Downloading shellingham-1.4.0-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (1.10.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (0.7.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (1.4.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->nemo_toolkit[all]) (8.8.0)\n",
      "Collecting ruamel.yaml.clib>=0.1.2\n",
      "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
      "\u001B[K     || 546 kB 47.7 MB/s \n",
      "\u001B[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting ipadic<2.0,>=1.0\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001B[K     || 13.4 MB 212 kB/s \n",
      "\u001B[?25hCollecting mecab-python3==1.0.3\n",
      "  Downloading mecab_python3-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (487 kB)\n",
      "\u001B[K     || 487 kB 43.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (0.7.12)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.2.4)\n",
      "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (0.17.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (2.1.0)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.2.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (2.9.1)\n",
      "Collecting pybtex-docutils>=1.0.0\n",
      "  Downloading pybtex_docutils-1.0.1-py3-none-any.whl (4.8 kB)\n",
      "Collecting pybtex>=0.20\n",
      "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
      "\u001B[K     || 561 kB 46.5 MB/s \n",
      "\u001B[?25hCollecting sphinx\n",
      "  Downloading Sphinx-4.2.0-py3-none-any.whl (3.1 MB)\n",
      "\u001B[K     || 3.1 MB 33.5 MB/s \n",
      "\u001B[?25hCollecting latexcodec>=1.0.4\n",
      "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001B[K     || 100 kB 9.4 MB/s \n",
      "\u001B[?25hCollecting sphinxcontrib-applehelp\n",
      "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
      "\u001B[K     || 121 kB 47.0 MB/s \n",
      "\u001B[?25hCollecting sphinxcontrib-devhelp\n",
      "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "\u001B[K     || 84 kB 3.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx->nemo_toolkit[all]) (1.1.5)\n",
      "Collecting sphinxcontrib-jsmath\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "\u001B[K     || 90 kB 9.3 MB/s \n",
      "\u001B[?25hCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (5.4.8)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->nemo_toolkit[all]) (2.3)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001B[K     || 170 kB 44.7 MB/s \n",
      "\u001B[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
      "\u001B[K     || 133 kB 46.0 MB/s \n",
      "\u001B[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001B[K     || 97 kB 6.3 MB/s \n",
      "\u001B[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001B[K     || 63 kB 1.6 MB/s \n",
      "\u001B[?25hCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: wordninja, antlr4-python3-runtime, fasttext, distance, kaldi-python-io, kaldiio, pesq, pystoi, ipadic, subprocess32, pathtools, wget\n",
      "  Building wheel for wordninja (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=045a30ef4a6316836f39b7e379cd812989fa0bde0514acfba1f4940925c1cd42\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=0d9292d27368d8876d6a866944cbd5e3d29f21b4cf6777fe9fe2718123b587ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
      "  Building wheel for fasttext (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3093311 sha256=23aa8c3a4124bdb6d0070ac847df66ff8dde9deeb38ab272699093f49b6def43\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
      "  Building wheel for distance (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16275 sha256=ceba904c651c166bafa8b301ae463edf80b184a95575cbab78da3d8b517ff8a0\n",
      "  Stored in directory: /root/.cache/pip/wheels/b2/10/1b/96fca621a1be378e2fe104cfb0d160bb6cdf3d04a3d35266cc\n",
      "  Building wheel for kaldi-python-io (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8968 sha256=e396b4462064260179f6e6e84451ff7e141e4a201c6babd53975c1ea0a9f2d9e\n",
      "  Stored in directory: /root/.cache/pip/wheels/a9/26/38/7678d1ff6cd1bbcbfc0d80b0a29d94d917dfa9ad790b4a85a9\n",
      "  Building wheel for kaldiio (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for kaldiio: filename=kaldiio-2.17.2-py3-none-any.whl size=24472 sha256=484b9ef3b8e9a27e1c54ca8fb9c209b2855906a465e1ec7d3faf0b1617cbf9df\n",
      "  Stored in directory: /root/.cache/pip/wheels/04/07/e8/45641287c59bf6ce41e22259f8680b521c31e6306cb88392ac\n",
      "  Building wheel for pesq (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pesq: filename=pesq-0.0.3-cp37-cp37m-linux_x86_64.whl size=209957 sha256=ac8f89d32950d97c64e9c0ac4a180437b14610e65c6cc704f417e17433d10c81\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/67/5b/aa7cf31fe0c7199e35c604bb7bc91c629a13726bf221fedba0\n",
      "  Building wheel for pystoi (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pystoi: filename=pystoi-0.3.3-py2.py3-none-any.whl size=7793 sha256=be66006f51b842376bdb6de5d39bd26595cebf01de78e1a48ff37d1f57983e7e\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/4a/ad/3ab460193ed0535430b4b1575f255aa6bae69df17453628e86\n",
      "  Building wheel for ipadic (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=f8658c7d6be5ff752aa791f1ddf2e22b9b32f868f38c1fca467180b9856094e9\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=edacff4c62017b8aacda7c963b1782435fb08ba7f31c0cfb468e2672390a122f\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "  Building wheel for pathtools (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=c0377f451b092a00c22ffe432716ccc6f6820d0316335a662b91c7e4456da36f\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "  Building wheel for wget (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=3a61a1e83ffd6c665d15c4e3a5136068671f0595494a15a7307275b2ae8654e2\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "Successfully built wordninja antlr4-python3-runtime fasttext distance kaldi-python-io kaldiio pesq pystoi ipadic subprocess32 pathtools wget\n",
      "Installing collected packages: urllib3, typer, smmap, simplejson, shellingham, matplotlib, latexcodec, jmespath, grpcio, colorama, antlr4-python3-runtime, yarg, tokenizers, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sacremoses, ruamel.yaml.clib, pybtex, pyannote.core, portalocker, omegaconf, huggingface-hub, gitdb, braceexpand, botocore, wget, webdataset, typed-ast, transformers, subprocess32, sphinx, shortuuid, sentry-sdk, sentencepiece, sacrebleu, s3transfer, ruamel.yaml, pybtex-docutils, pybind11, pyannote.database, pipreqs, pip-api, pathtools, pathspec, onnx, nltk, mecab-python3, isort, ipadic, hydra-core, grpcio-tools, GitPython, docker-pycreds, distance, configparser, youtokentome, wordninja, wandb, unidecode, torch-stft, sphinxcontrib-bibtex, sox, rapidfuzz, pytest-runner, pystoi, pypinyin, pydub, pyannote.metrics, pesq, parameterized, pangu, opencc, nemo-toolkit, megatron-lm, marshmallow, kaldiio, kaldi-python-io, kaldi-io, g2p-en, frozendict, fasttext, boto3, black, attrdict\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.2.2\n",
      "    Uninstalling matplotlib-3.2.2:\n",
      "      Successfully uninstalled matplotlib-3.2.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.39.0\n",
      "    Uninstalling grpcio-1.39.0:\n",
      "      Successfully uninstalled grpcio-1.39.0\n",
      "  Attempting uninstall: sphinx\n",
      "    Found existing installation: Sphinx 1.8.5\n",
      "    Uninstalling Sphinx-1.8.5:\n",
      "      Successfully uninstalled Sphinx-1.8.5\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001B[0m\n",
      "Successfully installed GitPython-3.1.18 antlr4-python3-runtime-4.8 attrdict-2.0.1 black-19.10b0 boto3-1.18.42 botocore-1.21.42 braceexpand-0.1.7 colorama-0.4.4 configparser-5.0.2 distance-0.1.3 docker-pycreds-0.4.0 fasttext-0.9.2 frozendict-2.0.6 g2p-en-2.1.0 gitdb-4.0.7 grpcio-1.40.0 grpcio-tools-1.40.0 huggingface-hub-0.0.17 hydra-core-1.1.1 ipadic-1.0.0 isort-4.3.21 jmespath-0.10.0 kaldi-io-0.9.4 kaldi-python-io-1.2.2 kaldiio-2.17.2 latexcodec-2.0.1 marshmallow-3.13.0 matplotlib-3.4.3 mecab-python3-1.0.3 megatron-lm-2.2.0 nemo-toolkit-1.3.0 nltk-3.6.2 omegaconf-2.1.1 onnx-1.10.1 opencc-1.1.2 pangu-4.0.6.1 parameterized-0.8.1 pathspec-0.9.0 pathtools-0.1.2 pesq-0.0.3 pip-api-0.0.21 pipreqs-0.4.10 portalocker-2.3.2 pyannote.core-4.1 pyannote.database-4.1.1 pyannote.metrics-3.0.1 pybind11-2.7.1 pybtex-0.24.0 pybtex-docutils-1.0.1 pydub-0.25.1 pypinyin-0.42.0 pystoi-0.3.3 pytest-runner-5.3.1 rapidfuzz-1.6.2 ruamel.yaml-0.17.16 ruamel.yaml.clib-0.2.6 s3transfer-0.5.0 sacrebleu-2.0.0 sacremoses-0.0.45 sentencepiece-0.1.96 sentry-sdk-1.3.1 shellingham-1.4.0 shortuuid-1.0.1 simplejson-3.17.5 smmap-4.0.0 sox-1.4.1 sphinx-4.2.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-bibtex-2.4.1 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 subprocess32-3.5.4 tokenizers-0.10.3 torch-stft-0.1.4 transformers-4.10.2 typed-ast-1.4.3 typer-0.4.0 unidecode-1.3.1 urllib3-1.25.11 wandb-0.12.1 webdataset-0.1.62 wget-3.2 wordninja-2.0.0 yarg-0.1.9 youtokentome-1.0.6\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits",
         "pydevd_plugins",
         "sphinxcontrib",
         "urllib3"
        ]
       }
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0rv7JjjHIax",
    "outputId": "494a84e1-373b-4118-e7ba-0d9f78edda2b"
   },
   "source": [
    "!git clone https://github.com/NVIDIA/apex\n",
    "%cd apex\n",
    "!pip install -v --disable-pip-version-check --no-cache-dir ./"
   ],
   "id": "n0rv7JjjHIax",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fatal: destination path 'apex' already exists and is not an empty directory.\n",
      "/content/apex\n",
      "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
      "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.7/dist-packages\n",
      "sysconfig: /usr/lib/python3.7/site-packages\n",
      "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.7/dist-packages\n",
      "sysconfig: /usr/lib/python3.7/site-packages\n",
      "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/include/python3.7/UNKNOWN\n",
      "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
      "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\n",
      "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\n",
      "Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "Non-user install because site-packages writeable\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-dx8d02ow\n",
      "Created temporary directory: /tmp/pip-req-tracker-7x3x7ycn\n",
      "Initialized build tracking at /tmp/pip-req-tracker-7x3x7ycn\n",
      "Created build tracker: /tmp/pip-req-tracker-7x3x7ycn\n",
      "Entered build tracker: /tmp/pip-req-tracker-7x3x7ycn\n",
      "Created temporary directory: /tmp/pip-install-f3eua8i5\n",
      "Processing /content/apex\n",
      "  Created temporary directory: /tmp/pip-req-build-pewfyfxk\n",
      "\u001B[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001B[0m\n",
      "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-7x3x7ycn'\n",
      "    Running setup.py (path:/tmp/pip-req-build-pewfyfxk/setup.py) egg_info for package from file:///content/apex\n",
      "    Created temporary directory: /tmp/pip-pip-egg-info-l0apie77\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.9.0+cu102\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-pip-egg-info-l0apie77/apex.egg-info\n",
      "    writing /tmp/pip-pip-egg-info-l0apie77/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-pip-egg-info-l0apie77/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-pip-egg-info-l0apie77/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-l0apie77/apex.egg-info/SOURCES.txt'\n",
      "    adding license file 'LICENSE'\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-l0apie77/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-pewfyfxk/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-pewfyfxk has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
      "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-7x3x7ycn'\n",
      "Created temporary directory: /tmp/pip-unpack-ucawtq_q\n",
      "Building wheels for collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-wheel-34a9dr9n\n",
      "  Building wheel for apex (setup.py) ... \u001B[?25l  Destination directory: /tmp/pip-wheel-34a9dr9n\n",
      "  Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-pewfyfxk/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-pewfyfxk/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-34a9dr9n\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.9.0+cu102\n",
      "\n",
      "\n",
      "  /tmp/pip-req-build-pewfyfxk/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  creating build/lib/apex\n",
      "  copying apex/__init__.py -> build/lib/apex\n",
      "  creating build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
      "  creating build/lib/apex/fused_dense\n",
      "  copying apex/fused_dense/fused_dense.py -> build/lib/apex/fused_dense\n",
      "  copying apex/fused_dense/__init__.py -> build/lib/apex/fused_dense\n",
      "  creating build/lib/apex/normalization\n",
      "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
      "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
      "  creating build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
      "  creating build/lib/apex/pyprof\n",
      "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
      "  creating build/lib/apex/RNN\n",
      "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
      "  creating build/lib/apex/contrib\n",
      "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
      "  creating build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  creating build/lib/apex/amp\n",
      "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
      "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
      "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
      "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
      "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
      "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
      "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
      "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
      "  creating build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
      "  creating build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
      "  creating build/lib/apex/mlp\n",
      "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
      "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
      "  creating build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
      "  creating build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
      "  creating build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
      "  creating build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
      "  creating build/lib/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
      "  creating build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  creating build/lib/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
      "  creating build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
      "  creating build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
      "  creating build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/bottleneck_module_test.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
      "  creating build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  creating build/lib/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
      "  creating build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
      "  installing to build/bdist.linux-x86_64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.linux-x86_64\n",
      "  creating build/bdist.linux-x86_64/wheel\n",
      "  creating build/bdist.linux-x86_64/wheel/apex\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "  copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "  copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/bottleneck_module_test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  creating apex.egg-info\n",
      "  writing apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "  writing top-level names to apex.egg-info/top_level.txt\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
      "  running install_scripts\n",
      "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
      "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
      "  creating '/tmp/pip-wheel-34a9dr9n/apex-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "  adding 'apex/__init__.py'\n",
      "  adding 'apex/RNN/RNNBackend.py'\n",
      "  adding 'apex/RNN/__init__.py'\n",
      "  adding 'apex/RNN/cells.py'\n",
      "  adding 'apex/RNN/models.py'\n",
      "  adding 'apex/amp/__init__.py'\n",
      "  adding 'apex/amp/__version__.py'\n",
      "  adding 'apex/amp/_amp_state.py'\n",
      "  adding 'apex/amp/_initialize.py'\n",
      "  adding 'apex/amp/_process_optimizer.py'\n",
      "  adding 'apex/amp/amp.py'\n",
      "  adding 'apex/amp/compat.py'\n",
      "  adding 'apex/amp/frontend.py'\n",
      "  adding 'apex/amp/handle.py'\n",
      "  adding 'apex/amp/opt.py'\n",
      "  adding 'apex/amp/rnn_compat.py'\n",
      "  adding 'apex/amp/scaler.py'\n",
      "  adding 'apex/amp/utils.py'\n",
      "  adding 'apex/amp/wrap.py'\n",
      "  adding 'apex/amp/lists/__init__.py'\n",
      "  adding 'apex/amp/lists/functional_overrides.py'\n",
      "  adding 'apex/amp/lists/tensor_overrides.py'\n",
      "  adding 'apex/amp/lists/torch_overrides.py'\n",
      "  adding 'apex/contrib/__init__.py'\n",
      "  adding 'apex/contrib/bottleneck/__init__.py'\n",
      "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
      "  adding 'apex/contrib/bottleneck/bottleneck_module_test.py'\n",
      "  adding 'apex/contrib/bottleneck/test.py'\n",
      "  adding 'apex/contrib/fmha/__init__.py'\n",
      "  adding 'apex/contrib/fmha/fmha.py'\n",
      "  adding 'apex/contrib/groupbn/__init__.py'\n",
      "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
      "  adding 'apex/contrib/layer_norm/__init__.py'\n",
      "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
      "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/optimizers/__init__.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
      "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
      "  adding 'apex/contrib/sparsity/__init__.py'\n",
      "  adding 'apex/contrib/sparsity/asp.py'\n",
      "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
      "  adding 'apex/contrib/transducer/__init__.py'\n",
      "  adding 'apex/contrib/transducer/transducer.py'\n",
      "  adding 'apex/contrib/xentropy/__init__.py'\n",
      "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
      "  adding 'apex/fp16_utils/__init__.py'\n",
      "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
      "  adding 'apex/fp16_utils/fp16util.py'\n",
      "  adding 'apex/fp16_utils/loss_scaler.py'\n",
      "  adding 'apex/fused_dense/__init__.py'\n",
      "  adding 'apex/fused_dense/fused_dense.py'\n",
      "  adding 'apex/mlp/__init__.py'\n",
      "  adding 'apex/mlp/mlp.py'\n",
      "  adding 'apex/multi_tensor_apply/__init__.py'\n",
      "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
      "  adding 'apex/normalization/__init__.py'\n",
      "  adding 'apex/normalization/fused_layer_norm.py'\n",
      "  adding 'apex/optimizers/__init__.py'\n",
      "  adding 'apex/optimizers/fused_adagrad.py'\n",
      "  adding 'apex/optimizers/fused_adam.py'\n",
      "  adding 'apex/optimizers/fused_lamb.py'\n",
      "  adding 'apex/optimizers/fused_novograd.py'\n",
      "  adding 'apex/optimizers/fused_sgd.py'\n",
      "  adding 'apex/parallel/LARC.py'\n",
      "  adding 'apex/parallel/__init__.py'\n",
      "  adding 'apex/parallel/distributed.py'\n",
      "  adding 'apex/parallel/multiproc.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
      "  adding 'apex/parallel/sync_batchnorm.py'\n",
      "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
      "  adding 'apex/pyprof/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
      "  adding 'apex/pyprof/parse/__init__.py'\n",
      "  adding 'apex/pyprof/parse/__main__.py'\n",
      "  adding 'apex/pyprof/parse/db.py'\n",
      "  adding 'apex/pyprof/parse/kernel.py'\n",
      "  adding 'apex/pyprof/parse/nvvp.py'\n",
      "  adding 'apex/pyprof/parse/parse.py'\n",
      "  adding 'apex/pyprof/prof/__init__.py'\n",
      "  adding 'apex/pyprof/prof/__main__.py'\n",
      "  adding 'apex/pyprof/prof/activation.py'\n",
      "  adding 'apex/pyprof/prof/base.py'\n",
      "  adding 'apex/pyprof/prof/blas.py'\n",
      "  adding 'apex/pyprof/prof/conv.py'\n",
      "  adding 'apex/pyprof/prof/convert.py'\n",
      "  adding 'apex/pyprof/prof/data.py'\n",
      "  adding 'apex/pyprof/prof/dropout.py'\n",
      "  adding 'apex/pyprof/prof/embedding.py'\n",
      "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
      "  adding 'apex/pyprof/prof/linear.py'\n",
      "  adding 'apex/pyprof/prof/loss.py'\n",
      "  adding 'apex/pyprof/prof/misc.py'\n",
      "  adding 'apex/pyprof/prof/normalization.py'\n",
      "  adding 'apex/pyprof/prof/optim.py'\n",
      "  adding 'apex/pyprof/prof/output.py'\n",
      "  adding 'apex/pyprof/prof/pointwise.py'\n",
      "  adding 'apex/pyprof/prof/pooling.py'\n",
      "  adding 'apex/pyprof/prof/prof.py'\n",
      "  adding 'apex/pyprof/prof/randomSample.py'\n",
      "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
      "  adding 'apex/pyprof/prof/reduction.py'\n",
      "  adding 'apex/pyprof/prof/softmax.py'\n",
      "  adding 'apex/pyprof/prof/usage.py'\n",
      "  adding 'apex/pyprof/prof/utility.py'\n",
      "  adding 'apex/reparameterization/__init__.py'\n",
      "  adding 'apex/reparameterization/reparameterization.py'\n",
      "  adding 'apex/reparameterization/weight_norm.py'\n",
      "  adding 'apex-0.1.dist-info/LICENSE'\n",
      "  adding 'apex-0.1.dist-info/METADATA'\n",
      "  adding 'apex-0.1.dist-info/WHEEL'\n",
      "  adding 'apex-0.1.dist-info/top_level.txt'\n",
      "  adding 'apex-0.1.dist-info/RECORD'\n",
      "  removing build/bdist.linux-x86_64/wheel\n",
      "\u001B[?25hdone\n",
      "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=211571 sha256=a367488637f957b716373af8e7b8635beb84b0dbeb2670779e54234daa8b6e57\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dx8d02ow/wheels/02/1d/54/16beaa489b73437cc70f3f4ef0bbaa36f0ac443dd94834df91\n",
      "Successfully built apex\n",
      "Installing collected packages: apex\n",
      "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/lib/python3.7/dist-packages\n",
      "  sysconfig: /usr/lib/python3.7/site-packages\n",
      "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/lib/python3.7/dist-packages\n",
      "  sysconfig: /usr/lib/python3.7/site-packages\n",
      "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/include/python3.7/apex\n",
      "  sysconfig: /usr/include/python3.7m/apex\n",
      "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/bin\n",
      "  sysconfig: /usr/bin\n",
      "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local\n",
      "  sysconfig: /usr\n",
      "  Additional context:\n",
      "  user = False\n",
      "  home = None\n",
      "  root = None\n",
      "  prefix = None\n",
      "\n",
      "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.7/dist-packages\n",
      "sysconfig: /usr/lib/python3.7/site-packages\n",
      "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.7/dist-packages\n",
      "sysconfig: /usr/lib/python3.7/site-packages\n",
      "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/include/python3.7/UNKNOWN\n",
      "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
      "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\n",
      "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\n",
      "Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "Successfully installed apex-0.1\n",
      "Removed build tracker: '/tmp/pip-req-tracker-7x3x7ycn'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bi6ONSv4FW_P",
    "outputId": "3c093ab6-e754-4f37-858c-2c6acbd3cff3"
   },
   "source": [
    "!wget --content-disposition https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_e2e_fastpitchhifigan/versions/1.0.0/zip -O tts_en_e2e_fastpitchhifigan_1.0.0.zip -P ~/checkpoints"
   ],
   "id": "bi6ONSv4FW_P",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-09-13 22:05:36--  https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_e2e_fastpitchhifigan/versions/1.0.0/zip\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 44.232.207.17, 44.238.121.239\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|44.232.207.17|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/nemo/models/tts_en_e2e_fastpitchhifigan/versions/1.0.0/files.zip?response-content-disposition=attachment%3B%20filename%3D%22files.zip%22&response-content-type=application%2Fzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEN3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJGMEQCIDF9l9ONqOWTqeHc2rnAnCgJhLUIf2N4noiW3jtFDi0HAiBkY3R9BKzERppMSO5dIqKu0UYHx71x1pqMmAwcniBlPir6Awg2EAMaDDc4OTM2MzEzNTAyNyIMkJSjnaN1APXHCgI5KtcDDSOz%2F5QhwhJjMCC9LdhNaCAGpOPUuzS6gcEQD9NhSrc8ZSdjDio2Gy1jz83F0IVSg%2FT8s2kd9lqCtoYaNbvYwV5bKZFIi4FHxRhjd22IEmM3zuHJNand81L%2FMdb1wtN7YM%2BI8CPNibR7JEwIL9E35Ntbflv%2BfbC%2B0%2FBf%2B0uirdnPUwaXGUtd%2FGsmeas%2BqCpyrj%2B2Z7q2VeIy7o9Vez1VUSimR4RkXGzs3RhoDehXEyfXVgDrJbD1o7wWJAaSUXZ%2B5ijZHhyXrJOBnJaMiV2Pf1K1CYFEUtZ6EyzQEQjri0zzpmo3auFUPgrKgFBKPqLACj0VzbxbF5EGcjr7Y%2FbM4ItCrhlG9Gu6ghvJ1DJrOtG8SKJMC7WPU%2FpBiAlTRbHY6wqK0Ppgxn1kaSWgOWnKNt5pvu69BSHIQmhu7TiR%2F6kN1ehvR4uZXIa42TFlAgWylimrZEaE1m1cfJYfidE485PqcaQv7y3%2FsBBdlJUK9ktRnanZJ67osz8igDlWDZb3w9Ed1SD3drCZ9IpQ0mbDtvfc1CGyLJ2YUeQocvoI1dUVZ18gbmFnVnlzcQMDCsu1bPWaf7htKgH%2BSeFYs8cYRPX8G3Lv6OB9m%2BQgovWUm8SQU02blNSgMJr0%2FokGOqYBs7ip7knOiJplCHNPKAsQZ5W9xm%2F1jJEXcKtfdBNcV3rBNHYB8nq1qXcD79yuWn%2Fpcxmap17VAocg5hzWtXmbAQsblmCXFaVLvohiXbhX39A45EahlKiMuFiL6Qvs%2BfBQNENA9BXrjoKZahcx4z%2BNeRqbdQYhXL4FT%2FLcQmTBWJ1sUi8NoNzbnOMgZrAHqzFokt%2BbGCx73lWrjarBGDWNXCMLDNQKiw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210913T220537Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZ5MRWDIVE%2F20210913%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=04f469f66f2670cc29d3dae403aacab539f056c37c4d5b688b0d24f99135e3f6 [following]\n",
      "--2021-09-13 22:05:37--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/nemo/models/tts_en_e2e_fastpitchhifigan/versions/1.0.0/files.zip?response-content-disposition=attachment%3B%20filename%3D%22files.zip%22&response-content-type=application%2Fzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEN3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJGMEQCIDF9l9ONqOWTqeHc2rnAnCgJhLUIf2N4noiW3jtFDi0HAiBkY3R9BKzERppMSO5dIqKu0UYHx71x1pqMmAwcniBlPir6Awg2EAMaDDc4OTM2MzEzNTAyNyIMkJSjnaN1APXHCgI5KtcDDSOz%2F5QhwhJjMCC9LdhNaCAGpOPUuzS6gcEQD9NhSrc8ZSdjDio2Gy1jz83F0IVSg%2FT8s2kd9lqCtoYaNbvYwV5bKZFIi4FHxRhjd22IEmM3zuHJNand81L%2FMdb1wtN7YM%2BI8CPNibR7JEwIL9E35Ntbflv%2BfbC%2B0%2FBf%2B0uirdnPUwaXGUtd%2FGsmeas%2BqCpyrj%2B2Z7q2VeIy7o9Vez1VUSimR4RkXGzs3RhoDehXEyfXVgDrJbD1o7wWJAaSUXZ%2B5ijZHhyXrJOBnJaMiV2Pf1K1CYFEUtZ6EyzQEQjri0zzpmo3auFUPgrKgFBKPqLACj0VzbxbF5EGcjr7Y%2FbM4ItCrhlG9Gu6ghvJ1DJrOtG8SKJMC7WPU%2FpBiAlTRbHY6wqK0Ppgxn1kaSWgOWnKNt5pvu69BSHIQmhu7TiR%2F6kN1ehvR4uZXIa42TFlAgWylimrZEaE1m1cfJYfidE485PqcaQv7y3%2FsBBdlJUK9ktRnanZJ67osz8igDlWDZb3w9Ed1SD3drCZ9IpQ0mbDtvfc1CGyLJ2YUeQocvoI1dUVZ18gbmFnVnlzcQMDCsu1bPWaf7htKgH%2BSeFYs8cYRPX8G3Lv6OB9m%2BQgovWUm8SQU02blNSgMJr0%2FokGOqYBs7ip7knOiJplCHNPKAsQZ5W9xm%2F1jJEXcKtfdBNcV3rBNHYB8nq1qXcD79yuWn%2Fpcxmap17VAocg5hzWtXmbAQsblmCXFaVLvohiXbhX39A45EahlKiMuFiL6Qvs%2BfBQNENA9BXrjoKZahcx4z%2BNeRqbdQYhXL4FT%2FLcQmTBWJ1sUi8NoNzbnOMgZrAHqzFokt%2BbGCx73lWrjarBGDWNXCMLDNQKiw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210913T220537Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZ5MRWDIVE%2F20210913%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=04f469f66f2670cc29d3dae403aacab539f056c37c4d5b688b0d24f99135e3f6\n",
      "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.216.241\n",
      "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.216.241|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 404183918 (385M) [application/zip]\n",
      "Saving to: tts_en_e2e_fastpitchhifigan_1.0.0.zip\n",
      "\n",
      "chhifigan_1.0.0.zip 100%[===================>] 385.46M  18.5MB/s    in 23s     \n",
      "\n",
      "2021-09-13 22:06:01 (16.9 MB/s) - tts_en_e2e_fastpitchhifigan_1.0.0.zip saved [404183918/404183918]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIgqMCaNMQLS",
    "outputId": "dd78b792-02af-4b89-e8b7-41bb6245a13c"
   },
   "source": [
    "!unzip ~/content/tts_en_e2e_fastpitchhifigan_1.0.0.zip -d ~/checkpoint"
   ],
   "id": "NIgqMCaNMQLS",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archive:  /root/checkpoint/tts_en_e2e_fastpitchhifigan_1.0.0.zip\n",
      "  inflating: tts_en_e2e_fastpitchhifigan.nemo  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BSSlzPfOKd_",
    "outputId": "35402bd6-69f3-41c0-e372-c35f5a493104"
   },
   "source": [
    "!gdown https://drive.google.com/uc?id=15FoehxQEZN8OSoIg8am7Wq-7vLS7QIgu"
   ],
   "id": "_BSSlzPfOKd_",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15FoehxQEZN8OSoIg8am7Wq-7vLS7QIgu\n",
      "To: /content/FastPitch-Align-LJSpeech.nemo\n",
      "170MB [00:01, 142MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_suoJ1JE4vP",
    "outputId": "0280cdd2-f483-49f8-9046-89f3564f05d5"
   },
   "source": [
    "!wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/tts/conf/fastpitch_align.yaml"
   ],
   "id": "q_suoJ1JE4vP",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-09-15 15:29:36--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/tts/conf/fastpitch_align.yaml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4728 (4.6K) [text/plain]\n",
      "Saving to: fastpitch_align.yaml\n",
      "\n",
      "\rfastpitch_align.yam   0%[                    ]       0  --.-KB/s               \rfastpitch_align.yam 100%[===================>]   4.62K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-09-15 15:29:36 (51.3 MB/s) - fastpitch_align.yaml saved [4728/4728]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7qzu3RnHpE1",
    "outputId": "0cfce6d6-34a3-4bd9-a5ed-40d4c41a977e"
   },
   "source": [
    "!python /content/capstone/finetune/fastpitch2_finetune.py --config-name=fastpitch_align.yaml train_dataset=/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json validation_datasets=/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json +init_from_nemo_model=/content/FastPitch-Align-LJSpeech.nemo trainer.max_epochs=10 trainer.check_val_every_n_epoch=1 prior_folder=/root/data/VCC2020-database/extract/target_task1/json/PriorsTEF1 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins model.n_speakers=1 model.optim.lr=2e-4 ~model.optim.sched"
   ],
   "id": "r7qzu3RnHpE1",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[NeMo W 2021-09-15 15:42:22 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text_dali._AudioTextDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "[NeMo I 2021-09-15 15:42:22 exp_manager:220] Experiments will be logged at /root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22\n",
      "[NeMo I 2021-09-15 15:42:22 exp_manager:569] TensorboardLogger has been set up\n",
      "[NeMo W 2021-09-15 15:42:22 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:241: LightningDeprecationWarning: `ModelCheckpoint(every_n_val_epochs)` is deprecated in v1.4 and will be removed in v1.6. Please use `every_n_epochs` instead.\n",
      "      \"`ModelCheckpoint(every_n_val_epochs)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "    \n",
      "[NeMo I 2021-09-15 15:42:24 collections:173] Dataset loaded with 70 files totalling 0.06 hours\n",
      "[NeMo I 2021-09-15 15:42:24 collections:174] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo W 2021-09-15 15:42:24 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      cpuset_checked))\n",
      "    \n",
      "[NeMo I 2021-09-15 15:42:26 collections:173] Dataset loaded with 70 files totalling 0.06 hours\n",
      "[NeMo I 2021-09-15 15:42:26 collections:174] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo W 2021-09-15 15:42:26 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      cpuset_checked))\n",
      "    \n",
      "[NeMo I 2021-09-15 15:42:28 features:252] PADDING: 1\n",
      "[NeMo I 2021-09-15 15:42:28 features:269] STFT using torch\n",
      "[NeMo W 2021-09-15 15:42:30 modelPT:131] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_train.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 32\n",
      "      num_workers: 12\n",
      "    \n",
      "[NeMo W 2021-09-15 15:42:30 modelPT:138] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset\n",
      "      manifest_filepath: /raid/LJSpeech/nvidia_ljspeech_val.json\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      int_values: false\n",
      "      normalize: true\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      sup_data_path: /raid/LJSpeech/prior\n",
      "      n_window_stride: 256\n",
      "      n_window_size: 1024\n",
      "      pitch_fmin: 80\n",
      "      pitch_fmax: 640\n",
      "      pitch_avg: 211.27540199742586\n",
      "      pitch_std: 52.1851002822779\n",
      "      vocab:\n",
      "        notation: phonemes\n",
      "        punct: true\n",
      "        spaces: true\n",
      "        stresses: true\n",
      "        add_blank_at: None\n",
      "        pad_with_space: true\n",
      "        chars: true\n",
      "        improved_version_g2p: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 32\n",
      "      num_workers: 8\n",
      "    \n",
      "[NeMo I 2021-09-15 15:42:32 features:252] PADDING: 1\n",
      "[NeMo I 2021-09-15 15:42:32 features:269] STFT using torch\n",
      "[NeMo I 2021-09-15 15:42:33 save_restore_connector:143] Model FastPitchModel was successfully restored from /content/FastPitch-Align-LJSpeech.nemo.\n",
      "[NeMo I 2021-09-15 15:42:33 modelPT:882] Model checkpoint restored from nemo file with path : `/content/FastPitch-Align-LJSpeech.nemo`\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for 1 nodes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All DDP processes registered. Starting ddp with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2021-09-15 15:42:35 modelPT:544] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        eps: 1e-08\n",
      "        lr: 0.0002\n",
      "        weight_decay: 1e-06\n",
      "    )\n",
      "[NeMo I 2021-09-15 15:42:35 lr_scheduler:496] Scheduler not initialized as no `sched` config supplied to setup_optimizer()\n",
      "\n",
      "  | Name             | Type                              | Params\n",
      "-----------------------------------------------------------------------\n",
      "0 | mel_loss         | MelLoss                           | 0     \n",
      "1 | pitch_loss       | PitchLoss                         | 0     \n",
      "2 | duration_loss    | DurationLoss                      | 0     \n",
      "3 | aligner          | AlignmentEncoder                  | 1.0 M \n",
      "4 | forward_sum_loss | ForwardSumLoss                    | 0     \n",
      "5 | bin_loss         | BinLoss                           | 0     \n",
      "6 | preprocessor     | AudioToMelSpectrogramPreprocessor | 0     \n",
      "7 | fastpitch        | FastPitchModule                   | 45.8 M\n",
      "-----------------------------------------------------------------------\n",
      "45.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "45.8 M    Total params\n",
      "183.035   Total estimated model params size (MB)\n",
      "Validation sanity check:   0% 0/2 [00:00<?, ?it/s][NeMo W 2021-09-15 15:43:41 patch_utils:50] torch.stft() signature has been updated for PyTorch 1.7+\n",
      "    Please update PyTorch to remain compatible with later versions of NeMo.\n",
      "[NeMo W 2021-09-15 15:43:44 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: \u001B[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\u001B[0m\n",
      "      warnings.warn(problem)\n",
      "    \n",
      "[NeMo W 2021-09-15 15:43:46 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      cpuset_checked))\n",
      "    \n",
      "[NeMo W 2021-09-15 15:43:46 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:327: UserWarning: The number of training samples (3) is smaller than the logging interval Trainer(log_every_n_steps=100). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "      f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n",
      "    \n",
      "Training: -1it [00:00, ?it/s][NeMo W 2021-09-15 15:43:46 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/lr_monitor.py:116: RuntimeWarning: You are using `LearningRateMonitor` callback with models that have no learning rate schedulers. Please see documentation for `configure_optimizers` method.\n",
      "      RuntimeWarning,\n",
      "    \n",
      "Epoch 0:   0% 0/6 [00:00<00:00, 3979.42it/s]  [W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0: 100% 6/6 [00:05<00:00,  1.19it/s]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A[NeMo W 2021-09-15 15:43:52 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      cpuset_checked))\n",
      "    \n",
      "\n",
      "Epoch 0: 100% 6/6 [00:08<00:00,  1.17s/it, loss=3.88, v_num=2-22]\n",
      "                                             \u001B[AEpoch 0, global step 2: v_loss reached 0.91696 (best 0.91696), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.92-epoch=0.ckpt\" as top 3\n",
      "[NeMo W 2021-09-15 15:44:01 nemo_logging:349] /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/callback_hook.py:103: LightningDeprecationWarning: The signature of `Callback.on_train_epoch_end` has changed in v1.3. `outputs` parameter has been removed. Support for the old signature will be removed in v1.5\n",
      "      \"The signature of `Callback.on_train_epoch_end` has changed in v1.3.\"\n",
      "    \n",
      "Epoch 1: 100% 6/6 [00:06<00:00,  1.11it/s, loss=3.88, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1: 100% 6/6 [00:08<00:00,  1.24s/it, loss=3.34, v_num=2-22]\n",
      "                                             \u001B[AEpoch 1, global step 5: v_loss reached 0.75130 (best 0.75130), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.75-epoch=1.ckpt\" as top 3\n",
      "Epoch 2: 100% 6/6 [00:06<00:00,  1.12it/s, loss=3.34, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2: 100% 6/6 [00:08<00:00,  1.24s/it, loss=3.03, v_num=2-22]\n",
      "                                             \u001B[AEpoch 2, global step 8: v_loss reached 0.62794 (best 0.62794), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.63-epoch=2.ckpt\" as top 3\n",
      "Epoch 3: 100% 6/6 [00:06<00:00,  1.12it/s, loss=3.03, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3: 100% 6/6 [00:08<00:00,  1.24s/it, loss=2.82, v_num=2-22]\n",
      "                                             \u001B[AEpoch 3, global step 11: v_loss reached 0.55013 (best 0.55013), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.55-epoch=3.ckpt\" as top 3\n",
      "Epoch 4: 100% 6/6 [00:06<00:00,  1.13it/s, loss=2.82, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 4: 100% 6/6 [00:08<00:00,  1.24s/it, loss=2.66, v_num=2-22]\n",
      "                                             \u001B[AEpoch 4, global step 14: v_loss reached 0.49894 (best 0.49894), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.50-epoch=4.ckpt\" as top 3\n",
      "Epoch 5: 100% 6/6 [00:06<00:00,  1.11it/s, loss=2.66, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5: 100% 6/6 [00:08<00:00,  1.24s/it, loss=2.53, v_num=2-22]\n",
      "                                             \u001B[AEpoch 5, global step 17: v_loss reached 0.45033 (best 0.45033), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.45-epoch=5.ckpt\" as top 3\n",
      "Epoch 6: 100% 6/6 [00:06<00:00,  1.13it/s, loss=2.53, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 6: 100% 6/6 [00:08<00:00,  1.23s/it, loss=2.32, v_num=2-22]\n",
      "                                             \u001B[AEpoch 6, global step 20: v_loss reached 0.41836 (best 0.41836), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.42-epoch=6.ckpt\" as top 3\n",
      "Epoch 7: 100% 6/6 [00:06<00:00,  1.13it/s, loss=2.32, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 7: 100% 6/6 [00:08<00:00,  1.24s/it, loss=2.07, v_num=2-22]\n",
      "                                             \u001B[AEpoch 7, global step 23: v_loss reached 0.39066 (best 0.39066), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.39-epoch=7.ckpt\" as top 3\n",
      "Epoch 8: 100% 6/6 [00:06<00:00,  1.12it/s, loss=2.07, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 8: 100% 6/6 [00:08<00:00,  1.24s/it, loss=1.93, v_num=2-22]\n",
      "                                             \u001B[AEpoch 8, global step 26: v_loss reached 0.35963 (best 0.35963), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.36-epoch=8.ckpt\" as top 3\n",
      "Epoch 9: 100% 6/6 [00:06<00:00,  1.12it/s, loss=1.93, v_num=2-22]  \n",
      "Validating: 0it [00:00, ?it/s]\u001B[A\n",
      "Validating:   0% 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 9: 100% 6/6 [00:08<00:00,  1.25s/it, loss=1.82, v_num=2-22]\n",
      "                                             \u001B[AEpoch 9, global step 29: v_loss reached 0.34603 (best 0.34603), saving model to \"/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-15_15-42-22/checkpoints/FastPitch--v_loss=0.35-epoch=9.ckpt\" as top 3\n",
      "Epoch 9: 100% 6/6 [00:26<00:00,  3.79s/it, loss=1.82, v_num=2-22]\n",
      "\u001B[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12b5511c"
   },
   "source": [
    "The generated command should look something like this. We can ofcourse tweak things like epochs/learning rate if we like\n",
    "\n",
    "`python examples/tts/fastpitch2_finetune.py --config-name=fastpitch_align_44100 train_dataset=filelists/92_mainifest_train_dur_5_mins_local.json validation_datasets=filelists/92_mainifest_dev_ns_all_local.json +init_from_nemo_model=PreTrainedModels/FastPitch.nemo trainer.max_epochs=1000 trainer.check_val_every_n_epoch=1 prior_folder=Hi_Fi_TTS_v_0/Priors92 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=inetuningDemo/8051_to_92_no_mixing_5_mins model.n_speakers=1 model.pitch_avg=214.5 model.pitch_std=30.9 model.pitch_fmin=80 model.pitch_fmax=512  model.optim.lr=2e-4 ~model.optim.sched`"
   ],
   "id": "12b5511c"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc30d1e2"
   },
   "source": [
    "^ Run the above command from the terminal from the `NeMo/` directory to start finetuning a model. "
   ],
   "id": "bc30d1e2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3bdf1ed"
   },
   "source": [
    "## Synthesize samples from finetuned checkpoints"
   ],
   "id": "c3bdf1ed"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2b46325"
   },
   "source": [
    "Once we have finetuned our FastPitch model, we can synthesize the audio samples for given text using the following inference steps. We use a HiFiGAN vocoder trained on multiple speakers, get the trained checkpoint path for our trained model and synthesize audio for a given text as follows."
   ],
   "id": "f2b46325"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "886c91dc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a3e0836c-2419-4f90-de74-be000a69d3de"
   },
   "source": [
    "from nemo.collections.tts.models import HifiGanModel\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "\n",
    "hifigan_ckpt_path =  \"/root/checkpoint\"\n",
    "# vocoder = HifiGanModel.load_from_checkpoint(hifigan_ckpt_path)\n",
    "vocoder = HifiGanModel.from_pretrained(\"tts_hifigan\")\n",
    "vocoder.eval().cuda()"
   ],
   "id": "886c91dc",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[NeMo I 2021-09-14 19:50:58 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.3.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n",
      "[NeMo I 2021-09-14 19:50:58 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.3.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo\n",
      "[NeMo I 2021-09-14 19:50:58 common:681] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[NeMo W 2021-09-14 19:51:07 modelPT:131] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n",
      "      min_duration: 0.75\n",
      "      n_segments: 8192\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2021-09-14 19:51:07 modelPT:138] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n",
      "      min_duration: 3\n",
      "      n_segments: 66150\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 5\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2021-09-14 19:51:07 features:230] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[NeMo I 2021-09-14 19:51:07 features:252] PADDING: 0\n",
      "[NeMo I 2021-09-14 19:51:07 features:269] STFT using torch\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[NeMo W 2021-09-14 19:51:07 features:230] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[NeMo I 2021-09-14 19:51:07 features:252] PADDING: 0\n",
      "[NeMo I 2021-09-14 19:51:07 features:269] STFT using torch\n",
      "[NeMo I 2021-09-14 19:51:09 save_restore_connector:143] Model HifiGanModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.3.0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HifiGanModel(\n",
       "  (audio_to_melspec_precessor): FilterbankFeatures()\n",
       "  (trg_melspec_fn): FilterbankFeatures()\n",
       "  (generator): Generator(\n",
       "    (conv_pre): Conv1d(80, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (ups): ModuleList(\n",
       "      (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "      (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "      (2): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (3): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "  )\n",
       "  (mpd): MultiPeriodDiscriminator(\n",
       "    (discriminators): ModuleList(\n",
       "      (0): DiscriminatorP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (1): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (2): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (3): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (4): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "        )\n",
       "        (conv_post): Conv2d(1024, 1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      )\n",
       "      (1): DiscriminatorP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (1): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (2): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (3): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (4): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "        )\n",
       "        (conv_post): Conv2d(1024, 1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      )\n",
       "      (2): DiscriminatorP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (1): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (2): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (3): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (4): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "        )\n",
       "        (conv_post): Conv2d(1024, 1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      )\n",
       "      (3): DiscriminatorP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (1): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (2): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (3): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (4): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "        )\n",
       "        (conv_post): Conv2d(1024, 1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      )\n",
       "      (4): DiscriminatorP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(1, 32, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (1): Conv2d(32, 128, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (2): Conv2d(128, 512, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (3): Conv2d(512, 1024, kernel_size=(5, 1), stride=(3, 1), padding=(2, 0))\n",
       "          (4): Conv2d(1024, 1024, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "        )\n",
       "        (conv_post): Conv2d(1024, 1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (msd): MultiScaleDiscriminator(\n",
       "    (discriminators): ModuleList(\n",
       "      (0): DiscriminatorS(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)\n",
       "          (2): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)\n",
       "          (3): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
       "          (4): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
       "          (5): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)\n",
       "          (6): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (conv_post): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (1): DiscriminatorS(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)\n",
       "          (2): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)\n",
       "          (3): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
       "          (4): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
       "          (5): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)\n",
       "          (6): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (conv_post): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "      (2): DiscriminatorS(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv1d(1, 128, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(41,), stride=(2,), padding=(20,), groups=4)\n",
       "          (2): Conv1d(128, 256, kernel_size=(41,), stride=(2,), padding=(20,), groups=16)\n",
       "          (3): Conv1d(256, 512, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
       "          (4): Conv1d(512, 1024, kernel_size=(41,), stride=(4,), padding=(20,), groups=16)\n",
       "          (5): Conv1d(1024, 1024, kernel_size=(41,), stride=(1,), padding=(20,), groups=16)\n",
       "          (6): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (conv_post): Conv1d(1024, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (meanpools): ModuleList(\n",
       "      (0): AvgPool1d(kernel_size=(4,), stride=(2,), padding=(2,))\n",
       "      (1): AvgPool1d(kernel_size=(4,), stride=(2,), padding=(2,))\n",
       "    )\n",
       "  )\n",
       "  (feature_loss): FeatureMatchingLoss()\n",
       "  (discriminator_loss): DiscriminatorLoss()\n",
       "  (generator_loss): GeneratorLoss()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0a4c986f"
   },
   "source": [
    "def infer(spec_gen_model, vocoder_model, str_input, speaker = None):\n",
    "    \"\"\"\n",
    "    Synthesizes spectrogram and audio from a text string given a spectrogram synthesis and vocoder model.\n",
    "    \n",
    "    Arguments:\n",
    "    spec_gen_model -- Instance of FastPitch model\n",
    "    vocoder_model -- Instance of a vocoder model (HiFiGAN in our case)\n",
    "    str_input -- Text input for the synthesis\n",
    "    speaker -- Speaker number (in the case of a multi-speaker model -- in the mixing case)\n",
    "    \n",
    "    Returns:\n",
    "    spectrogram, waveform of the synthesized audio.\n",
    "    \"\"\"\n",
    "    parser_model = spec_gen_model\n",
    "    with torch.no_grad():\n",
    "        parsed = parser_model.parse(str_input)\n",
    "        if speaker is not None:\n",
    "            speaker = torch.tensor([speaker]).long().cuda()\n",
    "        spectrogram = spec_gen_model.generate_spectrogram(tokens=parsed, speaker = speaker)\n",
    "        audio = vocoder_model.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "        \n",
    "    if spectrogram is not None:\n",
    "        if isinstance(spectrogram, torch.Tensor):\n",
    "            spectrogram = spectrogram.to('cpu').numpy()\n",
    "        if len(spectrogram.shape) == 3:\n",
    "            spectrogram = spectrogram[0]\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.to('cpu').numpy()\n",
    "    return spectrogram, audio\n",
    "\n",
    "def get_best_ckpt(experiment_base_dir, new_speaker_id, duration_mins, mixing_enabled, original_speaker_id):\n",
    "    \"\"\"\n",
    "    Gives the model checkpoint paths of an experiment  we ran. \n",
    "    \n",
    "    Arguments:\n",
    "    experiment_base_dir -- Base experiment directory (specified on top of this notebook as exp_base_dir)\n",
    "    new_speaker_id -- Speaker id of new HiFiTTS speaker we finetuned FastPitch on\n",
    "    duration_mins -- total minutes of the new speaker data\n",
    "    mixing_enabled -- True or False depending on whether we want to mix the original speaker data or not\n",
    "    original_speaker_id -- speaker id of the original HiFiTTS speaker\n",
    "    \n",
    "    Returns:\n",
    "    List of all checkpoint paths sorted by validation error, Last checkpoint path\n",
    "    \"\"\"\n",
    "    if not mixing_enabled:\n",
    "        exp_dir = \"{}/{}_to_{}_no_mixing_{}_mins\".format(experiment_base_dir, original_speaker_id, new_speaker_id, duration_mins)\n",
    "    else:\n",
    "        exp_dir = \"{}/{}_to_{}_mixing_{}_mins\".format(experiment_base_dir, original_speaker_id, new_speaker_id, duration_mins)\n",
    "    \n",
    "    ckpt_candidates = []\n",
    "    last_ckpt = None\n",
    "    for root, dirs, files in os.walk(exp_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ckpt\"):\n",
    "                val_error = float(file.split(\"v_loss=\")[1].split(\"-epoch\")[0])\n",
    "                if \"last\" in file:\n",
    "                    last_ckpt = os.path.join(root, file)\n",
    "                ckpt_candidates.append( (val_error, os.path.join(root, file)))\n",
    "    ckpt_candidates.sort()\n",
    "    \n",
    "    return ckpt_candidates, last_ckpt"
   ],
   "id": "0a4c986f",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0153bd5a"
   },
   "source": [
    "Specify the speaker id, duration mins and mixing variable to find the relevant checkpoint from the exp_base_dir and compare the synthesized audio with validation samples of the new speaker."
   ],
   "id": "0153bd5a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8901f88b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "outputId": "1b4ba935-cf31-47d5-88d2-117e90bc3120"
   },
   "source": [
    "new_speaker_id = \"TEF1\"\n",
    "duration_mins = 5\n",
    "mixing = False\n",
    "original_speaker_id = \"TEM1\"\n",
    "\n",
    "\n",
    "_ ,last_ckpt = get_best_ckpt(exp_base_dir, new_speaker_id, duration_mins, mixing, original_speaker_id)\n",
    "print(last_ckpt)\n",
    "\n",
    "cfg = {'name': 'FastPitch', 'sample_rate': 44100, 'train_dataset': '/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json', 'validation_datasets': '/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json', 'prior_folder': '/root/data/VCC2020-database/extract/target_task1/json/PriorsTEF1', 'model': {'learn_alignment': True, 'n_speakers': 1, 'symbols_embedding_dim': 384, 'max_token_duration': 75, 'n_mel_channels': 80, 'pitch_embedding_kernel_size': 3, 'n_window_size': 2048, 'n_window_stride': 512, 'fmax': None, 'pitch_fmin': 80, 'pitch_fmax': 640, 'pitch_avg': 211.27540199742586, 'pitch_std': 52.1851002822779, 'train_ds': {'dataset': {'_target_': 'nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset', 'manifest_filepath': '${train_dataset}', 'max_duration': None, 'min_duration': 0.1, 'int_values': False, 'normalize': True, 'sample_rate': '${sample_rate}', 'trim': False, 'sup_data_path': '${prior_folder}', 'n_window_stride': '${model.n_window_stride}', 'n_window_size': '${model.n_window_size}', 'pitch_fmin': '${model.pitch_fmin}', 'pitch_fmax': '${model.pitch_fmax}', 'pitch_avg': '${model.pitch_avg}', 'pitch_std': '${model.pitch_std}', 'vocab': {'notation': 'phonemes', 'punct': True, 'spaces': True, 'stresses': True, 'add_blank_at': 'None', 'pad_with_space': True, 'chars': True, 'improved_version_g2p': True}}, 'dataloader_params': {'drop_last': False, 'shuffle': True, 'batch_size': 24, 'num_workers': 12}}, 'validation_ds': {'dataset': {'_target_': 'nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset', 'manifest_filepath': '${validation_datasets}', 'max_duration': None, 'min_duration': None, 'int_values': False, 'normalize': True, 'sample_rate': '${sample_rate}', 'trim': False, 'sup_data_path': '${prior_folder}', 'n_window_stride': '${model.n_window_stride}', 'n_window_size': '${model.n_window_size}', 'pitch_fmin': '${model.pitch_fmin}', 'pitch_fmax': '${model.pitch_fmax}', 'pitch_avg': '${model.pitch_avg}', 'pitch_std': '${model.pitch_std}', 'vocab': {'notation': 'phonemes', 'punct': True, 'spaces': True, 'stresses': True, 'add_blank_at': 'None', 'pad_with_space': True, 'chars': True, 'improved_version_g2p': True}}, 'dataloader_params': {'drop_last': False, 'shuffle': False, 'batch_size': 24, 'num_workers': 8}}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'dither': 0.0, 'features': '${model.n_mel_channels}', 'frame_splicing': 1, 'highfreq': None, 'log': True, 'log_zero_guard_type': 'add', 'log_zero_guard_value': 1e-05, 'lowfreq': 0, 'mag_power': 1.0, 'n_fft': '${model.n_window_size}', 'n_window_size': '${model.n_window_size}', 'n_window_stride': '${model.n_window_stride}', 'normalize': None, 'pad_to': 1, 'pad_value': 0, 'preemph': None, 'sample_rate': '${sample_rate}', 'window': 'hann', 'window_size': None, 'window_stride': None}, 'input_fft': {'_target_': 'nemo.collections.tts.modules.transformer.FFTransformerEncoder', 'n_layer': 6, 'n_head': 1, 'd_model': '${model.symbols_embedding_dim}', 'd_head': 64, 'd_inner': 1536, 'kernel_size': 3, 'dropout': 0.1, 'dropatt': 0.1, 'dropemb': 0.0, 'd_embed': '${model.symbols_embedding_dim}'}, 'output_fft': {'_target_': 'nemo.collections.tts.modules.transformer.FFTransformerDecoder', 'n_layer': 6, 'n_head': 1, 'd_model': '${model.symbols_embedding_dim}', 'd_head': 64, 'd_inner': 1536, 'kernel_size': 3, 'dropout': 0.1, 'dropatt': 0.1, 'dropemb': 0.0}, 'alignment_module': {'_target_': 'nemo.collections.tts.modules.aligner.AlignmentEncoder', 'n_text_channels': '${model.symbols_embedding_dim}'}, 'duration_predictor': {'_target_': 'nemo.collections.tts.modules.fastpitch.TemporalPredictor', 'input_size': '${model.symbols_embedding_dim}', 'kernel_size': 3, 'filter_size': 256, 'dropout': 0.1, 'n_layers': 2}, 'pitch_predictor': {'_target_': 'nemo.collections.tts.modules.fastpitch.TemporalPredictor', 'input_size': '${model.symbols_embedding_dim}', 'kernel_size': 3, 'filter_size': 256, 'dropout': 0.1, 'n_layers': 2}, 'optim': {'name': 'adam', 'lr': 0.0002, 'betas': [0.9, 0.98], 'weight_decay': 1e-06}}, 'trainer': {'gpus': -1, 'max_epochs': 10, 'num_nodes': 1, 'accelerator': 'ddp', 'accumulate_grad_batches': 1, 'checkpoint_callback': False, 'logger': False, 'gradient_clip_val': 1000.0, 'flush_logs_every_n_steps': 1000, 'log_every_n_steps': 100, 'check_val_every_n_epoch': 1}, 'exp_manager': {'exp_dir': '/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins', 'name': '${name}', 'create_tensorboard_logger': True, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'monitor': 'v_loss'}}, 'init_from_ptl_ckpt': '/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-14_19-16-49/checkpoints/FastPitch--v_loss=17.86-epoch=9-last.ckpt'}\n",
    "spec_model = FastPitchModel.load_from_checkpoint(last_ckpt)#, cfg={'name': 'FastPitch', 'sample_rate': 44100, 'train_dataset': '/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json', 'validation_datasets': '/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json', 'prior_folder': '/root/data/VCC2020-database/extract/target_task1/json/PriorsTEF1', 'model': {'learn_alignment': True, 'n_speakers': 1, 'symbols_embedding_dim': 384, 'max_token_duration': 75, 'n_mel_channels': 80, 'pitch_embedding_kernel_size': 3, 'n_window_size': 2048, 'n_window_stride': 512, 'fmax': None, 'pitch_fmin': 80, 'pitch_fmax': 640, 'pitch_avg': 211.27540199742586, 'pitch_std': 52.1851002822779, 'train_ds': {'dataset': {'_target_': 'nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset', 'manifest_filepath': '${train_dataset}', 'max_duration': None, 'min_duration': 0.1, 'int_values': False, 'normalize': True, 'sample_rate': '${sample_rate}', 'trim': False, 'sup_data_path': '${prior_folder}', 'n_window_stride': '${model.n_window_stride}', 'n_window_size': '${model.n_window_size}', 'pitch_fmin': '${model.pitch_fmin}', 'pitch_fmax': '${model.pitch_fmax}', 'pitch_avg': '${model.pitch_avg}', 'pitch_std': '${model.pitch_std}', 'vocab': {'notation': 'phonemes', 'punct': True, 'spaces': True, 'stresses': True, 'add_blank_at': 'None', 'pad_with_space': True, 'chars': True, 'improved_version_g2p': True}}, 'dataloader_params': {'drop_last': False, 'shuffle': True, 'batch_size': 24, 'num_workers': 12}}, 'validation_ds': {'dataset': {'_target_': 'nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset', 'manifest_filepath': '${validation_datasets}', 'max_duration': None, 'min_duration': None, 'int_values': False, 'normalize': True, 'sample_rate': '${sample_rate}', 'trim': False, 'sup_data_path': '${prior_folder}', 'n_window_stride': '${model.n_window_stride}', 'n_window_size': '${model.n_window_size}', 'pitch_fmin': '${model.pitch_fmin}', 'pitch_fmax': '${model.pitch_fmax}', 'pitch_avg': '${model.pitch_avg}', 'pitch_std': '${model.pitch_std}', 'vocab': {'notation': 'phonemes', 'punct': True, 'spaces': True, 'stresses': True, 'add_blank_at': 'None', 'pad_with_space': True, 'chars': True, 'improved_version_g2p': True}}, 'dataloader_params': {'drop_last': False, 'shuffle': False, 'batch_size': 24, 'num_workers': 8}}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'dither': 0.0, 'features': '${model.n_mel_channels}', 'frame_splicing': 1, 'highfreq': None, 'log': True, 'log_zero_guard_type': 'add', 'log_zero_guard_value': 1e-05, 'lowfreq': 0, 'mag_power': 1.0, 'n_fft': '${model.n_window_size}', 'n_window_size': '${model.n_window_size}', 'n_window_stride': '${model.n_window_stride}', 'normalize': None, 'pad_to': 1, 'pad_value': 0, 'preemph': None, 'sample_rate': '${sample_rate}', 'window': 'hann', 'window_size': None, 'window_stride': None}, 'input_fft': {'_target_': 'nemo.collections.tts.modules.transformer.FFTransformerEncoder', 'n_layer': 6, 'n_head': 1, 'd_model': '${model.symbols_embedding_dim}', 'd_head': 64, 'd_inner': 1536, 'kernel_size': 3, 'dropout': 0.1, 'dropatt': 0.1, 'dropemb': 0.0, 'd_embed': '${model.symbols_embedding_dim}'}, 'output_fft': {'_target_': 'nemo.collections.tts.modules.transformer.FFTransformerDecoder', 'n_layer': 6, 'n_head': 1, 'd_model': '${model.symbols_embedding_dim}', 'd_head': 64, 'd_inner': 1536, 'kernel_size': 3, 'dropout': 0.1, 'dropatt': 0.1, 'dropemb': 0.0}, 'alignment_module': {'_target_': 'nemo.collections.tts.modules.aligner.AlignmentEncoder', 'n_text_channels': '${model.symbols_embedding_dim}'}, 'duration_predictor': {'_target_': 'nemo.collections.tts.modules.fastpitch.TemporalPredictor', 'input_size': '${model.symbols_embedding_dim}', 'kernel_size': 3, 'filter_size': 256, 'dropout': 0.1, 'n_layers': 2}, 'pitch_predictor': {'_target_': 'nemo.collections.tts.modules.fastpitch.TemporalPredictor', 'input_size': '${model.symbols_embedding_dim}', 'kernel_size': 3, 'filter_size': 256, 'dropout': 0.1, 'n_layers': 2}, 'optim': {'name': 'adam', 'lr': 0.0002, 'betas': [0.9, 0.98], 'weight_decay': 1e-06}}, 'trainer': {'gpus': -1, 'max_epochs': 10, 'num_nodes': 1, 'accelerator': 'ddp', 'accumulate_grad_batches': 1, 'checkpoint_callback': False, 'logger': False, 'gradient_clip_val': 1000.0, 'flush_logs_every_n_steps': 1000, 'log_every_n_steps': 100, 'check_val_every_n_epoch': 1}, 'exp_manager': {'exp_dir': '/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins', 'name': '${name}', 'create_tensorboard_logger': True, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'monitor': 'v_loss'}}, 'init_from_ptl_ckpt': '/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-14_19-16-49/checkpoints/FastPitch--v_loss=17.86-epoch=9-last.ckpt'})\n",
    "spec_model.eval().cuda()\n",
    "_speaker=None\n",
    "if mixing:\n",
    "    _speaker = 1\n",
    "\n",
    "num_val = 2\n",
    "\n",
    "manifest_path = os.path.join(filelist_dir, \"{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id))\n",
    "val_records = []\n",
    "with open(manifest_path, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        val_records.append( json.loads(line) )\n",
    "        if len(val_records) >= num_val:\n",
    "            break\n",
    "            \n",
    "for val_record in val_records:\n",
    "    print (\"Real validation audio\")\n",
    "    ipd.display(ipd.Audio(val_record['audio_filepath'], rate=44100))\n",
    "    print (\"SYNTHESIZED FOR -- Speaker: {} | Dataset size: {} mins | Mixing:{} | Text: {}\".format(new_speaker_id, duration_mins, mixing, val_record['text']))\n",
    "    spec, audio = infer(spec_model, vocoder, val_record['text'], speaker = _speaker)\n",
    "    ipd.display(ipd.Audio(audio, rate=44100))\n",
    "    %matplotlib inline\n",
    "    #if spec is not None:\n",
    "    imshow(spec, origin=\"lower\", aspect = \"auto\")\n",
    "    plt.show()"
   ],
   "id": "8901f88b",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/root/data/VCC2020-database/extract/target_task1/exp_base/TEM1_to_TEF1_no_mixing_5_mins/FastPitch/2021-09-14_20-00-56/checkpoints/FastPitch--v_loss=7.88-epoch=9-last.ckpt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-42-73c54cc26a8b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mcfg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'name'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'FastPitch'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'sample_rate'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m44100\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'train_dataset'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'validation_datasets'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'prior_folder'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'/root/data/VCC2020-database/extract/target_task1/json/PriorsTEF1'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'model'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'learn_alignment'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'n_speakers'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'symbols_embedding_dim'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m384\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'max_token_duration'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m75\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'n_mel_channels'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m80\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'pitch_embedding_kernel_size'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'n_window_size'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m2048\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'n_window_stride'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m512\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'fmax'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'pitch_fmin'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m80\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'pitch_fmax'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m640\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'pitch_avg'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m211.27540199742586\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;...\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mspec_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFastPitchModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_from_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlast_ckpt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m#, cfg={'name': 'FastPitch', 'sample_rate': 44100, 'train_dataset': '/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json', 'validation_datasets': '/root/data/VCC2020-database/extract/target_task1/filelist/TEF1_metadata_dur_5_mins_local.json', 'prior_folder': '/root/data/VCC2020-database/extract/target_task1/json/PriorsTEF1', 'model': {'learn_alignment': True, 'n_speakers': 1, 'symbols_embedding_dim': 384, 'max_token_duration': 75, 'n_mel_channels': 80, 'pitch_embedding_kernel_size': 3, 'n_window_size': 2048, 'n_window_stride': 512, 'fmax': None, 'pitch_fmin': 80, 'pitch_fmax': 640, 'pitch_avg': 211.27540199742586, 'pitch_std': 52.1851002822779, 'train_ds': {'dataset': {'_target_': 'nemo.collections.asr.data.audio_to_text.AudioToCharWithPriorAndPitchDataset', 'manifest_filepath': '${train_dataset}', 'max_duration': None, 'min_duration': 0.1, 'int_values': False, 'normalize': True, 'sample_rate': '${sample_rate}', 'trim': False, 'sup_data_path': '${prior_folder}', 'n_window_stride': '${model.n_window_stride}', 'n_window_size': '${model.n_window_size}', 'pitch_fmin': '${model.pitch_fmin}', 'pitch_fmax': '${model.pitch_fmax}', 'pitch_avg': '${model.pitch_avg}', 'pitch_std': '${model.pitch_std}', 'vocab': {'notation': 'phonemes', 'punct': True, 'spaces': True, 'stresses': Tru...\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;31m#spec_model = FastPitchModel.restore_from(last_ckpt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;31m# spec_model = FastPitchModel(cfg=cfg['model'])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/nemo/core/classes/modelPT.py\u001B[0m in \u001B[0;36mload_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, *args, **kwargs)\u001B[0m\n\u001B[1;32m    299\u001B[0m                 \u001B[0mhparams_file\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhparams_file\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m                 \u001B[0mstrict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstrict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m                 \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m             )\n\u001B[1;32m    303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/saving.py\u001B[0m in \u001B[0;36mload_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m         \u001B[0mcheckpoint\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCHECKPOINT_HYPER_PARAMS_KEY\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_load_model_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstrict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstrict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    154\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/saving.py\u001B[0m in \u001B[0;36m_load_model_state\u001B[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001B[0m\n\u001B[1;32m    193\u001B[0m             \u001B[0m_cls_kwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_cls_kwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcls_init_args_name\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 195\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0m_cls_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m         \u001B[0;31m# give model a chance to load something\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'cfg'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "18ce524f"
   },
   "source": [
    ""
   ],
   "id": "18ce524f",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k_tlCr2WwGhf"
   },
   "source": [
    ""
   ],
   "id": "k_tlCr2WwGhf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6o_p59kU3wDL"
   },
   "source": [
    ""
   ],
   "id": "6o_p59kU3wDL",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IfMtnr4EpxK7"
   },
   "source": [
    "from nemo.collections.tts.models import FastPitchModel, HifiGanModel \n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "\n",
    "fp = FastPitchModel.restore_from(\"./FastPitch-Align-LJSpeech.nemo\")  # The file shared above\n",
    "hf = HifiGanModel.from_pretrained(\"tts_hifigan\")  # This will fetch our publicily available model from the cloud\n",
    "\n",
    "tokens = fp.parse(\"Can you speak to me?\").cuda()\n",
    "with torch.no_grad():\n",
    "    spectrogram = fp.generate_spectrogram(tokens=tokens)\n",
    "    audio = hf(spec=spectrogram).squeeze(1)\n",
    "ipd.display(ipd.Audio(audio.cpu().numpy(), rate=22050))\n"
   ],
   "id": "IfMtnr4EpxK7",
   "execution_count": null,
   "outputs": []
  }
 ]
}